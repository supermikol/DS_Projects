{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imblearn.over_sampling\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_products_dtype={\n",
    "    'order_id': np.int32, \n",
    "    'product_id': np.int32,\n",
    "    'add_to_cart_order': np.int16,\n",
    "    'reordered': np.int8\n",
    "}\n",
    "\n",
    "orders_products_prior_df = pd.read_csv('./data/order_products__prior.csv', dtype=orders_products_dtype)\n",
    "orders_products_train_df = pd.read_csv('./data/order_products__train.csv', dtype=orders_products_dtype)\n",
    "\n",
    "orders_dtype = {\n",
    "    'order_id': np.int32,\n",
    "    'user_id': np.int32,\n",
    "    'order_number': np.int16,\n",
    "    'order_dow': np.int8,\n",
    "    'order_hour_of_day': np.int8,\n",
    "    'days_since_prior_order': np.float16\n",
    "}\n",
    "orders_df = pd.read_csv('./data/orders.csv', dtype=orders_dtype)\n",
    "\n",
    "aisles_dtype = {\n",
    "    'aisle_id': np.int16\n",
    "}\n",
    "aisles_df = pd.read_csv('./data/aisles.csv', dtype=aisles_dtype)\n",
    "\n",
    "departments_dtype={\n",
    "    'department_id': np.int8\n",
    "}\n",
    "departments_df = pd.read_csv('./data/departments.csv', dtype=departments_dtype)\n",
    "\n",
    "products_dtype = {\n",
    "    'product_id': np.int32,\n",
    "    'aisle_id': np.int16,\n",
    "    'department_id': np.int8\n",
    "}\n",
    "products_df = pd.read_csv('./data/products.csv', dtype=products_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique user_id in train set where current basket exists\n",
    "orders_products_train_df = orders_products_train_df.merge(orders_df.drop(['eval_set'], axis=1), on='order_id')\n",
    "unique_current_user_ids = orders_products_train_df.user_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column in PRIOR to track if user has a current order\n",
    "orders_products_prior_df = orders_products_prior_df.merge(orders_df.drop(['eval_set'], axis=1), on='order_id')\n",
    "orders_products_prior_df['has_current_order'] = orders_products_prior_df['user_id'].isin(unique_current_user_ids)\n",
    "\n",
    "# Keep only rows where user has current basket\n",
    "orders_products_prior_filtered_df = orders_products_prior_df[orders_products_prior_df['has_current_order']].drop(['has_current_order'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER PRODUCT FEATURES\n",
    "from collections import OrderedDict\n",
    "from itertools import groupby\n",
    "# user_product_features = ['user_total_orders','user_avg_cartsize','user_total_products','user_avg_days_since_prior_order']\n",
    "\n",
    "df_X = (orders_products_prior_df.groupby(['user_id', 'product_id'],as_index=False)\n",
    "                                           .agg(OrderedDict(\n",
    "                                                   [('order_id','nunique'),\n",
    "                                                    ('add_to_cart_order', 'median'),\n",
    "                                                    ('order_hour_of_day','mean'),\n",
    "                                                    ('days_since_prior_order','mean'),\n",
    "                                                    ('reordered', (lambda x: tuple(x)))]\n",
    "                                           )))\n",
    "\n",
    "df_X.columns = ['user_id', 'product_id', 'user_product_times_ordered', 'user_product_add_to_cart_order_median', 'user_product_hour_of_day_mean', 'user_product_average_days_since_prior_order', 'reordered_history'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate whether last time reordered and longest reorder streak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_X['last_reorder'] = df_X['reordered_history'].map(lambda x: x[-1])\n",
    "def find_max_reorders(reorder_tuple):\n",
    "    count_dups = [len(list(group)) for k, group in groupby(reorder_tuple) if k]\n",
    "    try:\n",
    "        return max(count_dups)\n",
    "    except: \n",
    "        return 0\n",
    "df_X['max_consec_reorders'] = df_X['reordered_history'].map(find_max_reorders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.drop(['reordered_history'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Training Label Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Training Label Column\n",
    "train_carts = (orders_products_train_df.groupby('user_id',as_index=False)\n",
    "                                      .agg({'product_id':(lambda x: set(x))})\n",
    "                                      .rename(columns={'product_id':'latest_cart'}))\n",
    "df_X = df_X.merge(train_carts, on='user_id')\n",
    "df_X['in_cart'] = (df_X.apply(lambda row: row['product_id'] in row['latest_cart'], axis=1).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior = pd.read_csv('./data/order_products__prior.csv', dtype=orders_products_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/order_products__train.csv', dtype=orders_products_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.read_csv('./data/orders.csv', dtype=orders_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp[df_temp['eval_set'] == 'test'].sort_values('order_id').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('./data/sample_submission.csv', dtype=orders_products_dtype).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_temp[df_temp['user_id'] == 1])\n",
    "print(df_temp[df_temp['user_id'] == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['order_id'] == 1492625].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior[df_prior['order_id'] == 1374495].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior[df_prior['order_id'] == 444309].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior[df_prior['order_id'] == 3002854].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More (User Specific) Features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER FEATURES\n",
    "from collections import OrderedDict\n",
    "\n",
    "user_features = ['user_total_orders','user_avg_cartsize','user_total_products','user_avg_days_since_prior_order']\n",
    "\n",
    "df_user_features = (orders_products_prior_df.groupby(['user_id'],as_index=False)\n",
    "                                           .agg(OrderedDict(\n",
    "                                                   [('order_id',['nunique', (lambda x: x.shape[0] / x.nunique())]),\n",
    "                                                    ('product_id','nunique'),\n",
    "                                                    ('days_since_prior_order','mean')]\n",
    "                                           )))\n",
    "\n",
    "df_user_features.columns = ['user_id'] + user_features\n",
    "# df_user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge user feature columns\n",
    "df_X = df_X.merge(df_user_features, on=['user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.isnull().sum().plot(kind='barh')\n",
    "plt.title('Number of NaN values per feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X['user_product_average_days_since_prior_order'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bins for `user_product_average_days_since_prior_order`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bin(x):\n",
    "    if x < 5:\n",
    "        return 0\n",
    "    elif x < 10:\n",
    "        return 1\n",
    "    elif x < 15:\n",
    "        return 2\n",
    "    elif x < 20:\n",
    "        return 3\n",
    "    elif x < 25:\n",
    "        return 4\n",
    "    elif x <= 30:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6\n",
    "\n",
    "mapped_df = df_X['user_product_average_days_since_prior_order'].map(convert_to_bin)\n",
    "up_adspo_bins = pd.get_dummies(mapped_df)\n",
    "up_adspo_bins.columns = ['usadspo_0-5', 'usadspo_5-10', 'usadspo_10-15', 'usadspo_15-20', 'usadspo_20-25', 'usadspo_25-30', 'usadspo_firstTime']\n",
    "df_X = pd.concat([df_X, up_adspo_bins], axis=1)\n",
    "# df_X.drop(['user_product_average_days_since_prior_order'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_labels = ['usadspo_0-5', 'usadspo_5-10', 'usadspo_10-15', \n",
    "         'usadspo_15-20', 'usadspo_20-25', 'usadspo_25-30', \n",
    "         'usadspo_firstTime']\n",
    "plt.figure(figsize=(8,5))\n",
    "df_X[plot_labels].apply('sum', axis=0).plot(kind='barh');\n",
    "plt.title('Bin Distribution of Average Days Since Prior Order')\n",
    "plt.yticks(np.arange(len(plot_labels)), ['0-5', '5-10', '10-15', 'l5-20', '20-25','25-30', 'First Time Ordering'])\n",
    "plt.ylabel('Days Since Last Order')\n",
    "plt.xlabel('Order Count')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Product Detail Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature Dataframe for Products\n",
    "products_df = products_df.merge(departments_df, on='department_id').merge(aisles_df, on='aisle_id').drop(['product_name','aisle_id','department_id'], axis=1)\n",
    "products_df_departments = pd.concat([products_df, pd.get_dummies(products_df['department'])], axis=1).drop(['department','aisle'], axis=1)\n",
    "products_df_aisles = pd.concat([products_df, pd.get_dummies(products_df['aisle'])], axis=1).drop(['department','aisle'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge department feature columns\n",
    "df_X = df_X.merge(products_df_departments, on=['product_id'])\n",
    "# Merge aisle feature columns\n",
    "df_X = df_X.merge(products_df_aisles, on=['product_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix,accuracy_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE SUBSET OF USERS\n",
    "np.random.seed(153)\n",
    "total_users = df_X['user_id'].unique() \n",
    "user_subset = np.random.choice(total_users, size=int(total_users.shape[0] * .05), replace=False)\n",
    "\n",
    "df_subset = df_X[df_X['user_id'].isin(user_subset)] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Train Test Split with subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test train split with subset 70/30\n",
    "np.random.seed(48)\n",
    "subset_total_users = df_subset['user_id'].unique() \n",
    "test_set = np.random.choice(subset_total_users, size=int(subset_total_users.shape[0] * .30), replace=False)\n",
    "\n",
    "df_X_tr, df_X_te = df_subset[~df_subset['user_id'].isin(test_set)], df_subset[df_subset['user_id'].isin(test_set)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check weights\n",
    "df_X.in_cart.value_counts(normalize=True).plot(kind='barh');\n",
    "plt.title('Proportion of Products Reordered (Label)')\n",
    "plt.xlabel('Proportion')\n",
    "plt.yticks([0,1], ['Not Reordered', 'Reordered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training with single feature\n",
    "feature_columns = ['user_total_orders']\n",
    "y_tr, y_te = df_X_tr['in_cart'], df_X_te['in_cart']\n",
    "X_tr, X_te = df_X_tr[feature_columns], \\\n",
    "             df_X_te[feature_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Data\n",
    "scaler = StandardScaler()\n",
    "X_tr = scaler.fit_transform(X_tr)\n",
    "X_te = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_tr, y_tr)\n",
    "print('Simple Logistic Regression; Test F1: %.3f, Test AUC: %.3f' % \\\n",
    "      (f1_score(lr.predict(X_te), y_te), roc_auc_score(y_te, lr.predict_proba(X_te)[:,1]))) \n",
    "\n",
    "\n",
    "# Oversample positive samples to be 40% of targets \n",
    "ROS = imblearn.over_sampling.RandomOverSampler(random_state=159)\n",
    "X_tr_rs, y_tr_rs = ROS.fit_sample(X_tr, y_tr)\n",
    "\n",
    "lr_os = LogisticRegression() \n",
    "lr_os.fit(X_tr_rs, y_tr_rs)\n",
    "\n",
    "print('Logistic Regression on Oversampled Train Data; Test F1: %.3f, Test AUC: %.3f' % \\\n",
    "      (f1_score(lr_os.predict(X_te), y_te), roc_auc_score(y_te, lr_os.predict_proba(X_te)[:,1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\n",
    "    'user_product_times_ordered',\n",
    "    'user_product_add_to_cart_order_median',\n",
    "    'user_product_hour_of_day_mean',\n",
    "    'user_total_orders',\n",
    "    'user_avg_cartsize',\n",
    "    'user_total_products',\n",
    "    'user_avg_days_since_prior_order', \n",
    "    ['usadspo_0-5', 'usadspo_5-10', 'usadspo_10-15', \n",
    "         'usadspo_15-20', 'usadspo_20-25', 'usadspo_25-30', \n",
    "         'usadspo_firstTime'],\n",
    "    'last_reorder',\n",
    "    'max_consec_reorders',\n",
    "    ['alcohol', 'babies', 'bakery', 'beverages',\n",
    "        'breakfast', 'bulk', 'canned goods', 'dairy eggs', 'deli',\n",
    "        'dry goods pasta', 'frozen', 'household', 'international',\n",
    "        'meat seafood', 'pantry', 'personal care', 'pets',\n",
    "        'produce', 'snacks'],\n",
    "    ['air fresheners candles', 'asian foods', \n",
    "    'baby accessories', 'baby bath body care', \n",
    "    'baby food formula', 'bakery desserts', \n",
    "    'baking ingredients', 'baking supplies decor', \n",
    "    'beauty', 'beers coolers', 'body lotions soap', \n",
    "    'bread', 'breakfast bakery', 'breakfast bars pastries', \n",
    "    'bulk dried fruits vegetables', 'bulk grains rice dried goods', \n",
    "    'buns rolls', 'butter', 'candy chocolate', \n",
    "    'canned fruit applesauce', 'canned jarred vegetables', \n",
    "    'canned meals beans', 'canned meat seafood', \n",
    "    'cat food care', 'cereal', 'chips pretzels', \n",
    "    'cleaning products', 'cocoa drink mixes', \n",
    "    'coffee', 'cold flu allergy', 'condiments', \n",
    "    'cookies cakes', 'crackers', 'cream', 'deodorants', \n",
    "    'diapers wipes', 'digestion', 'dish detergents', \n",
    "    'dog food care', 'doughs gelatins bake mixes', \n",
    "    'dry pasta', 'eggs', 'energy granola bars', \n",
    "    'energy sports drinks', 'eye ear care', \n",
    "    'facial care', 'feminine care', 'first aid', \n",
    "    'food storage', 'fresh dips tapenades', \n",
    "    'fresh fruits', 'fresh herbs', 'fresh pasta', \n",
    "    'fresh vegetables', 'frozen appetizers sides', \n",
    "    'frozen breads doughs', 'frozen breakfast', \n",
    "    'frozen dessert', 'frozen juice', 'frozen meals', \n",
    "    'frozen meat seafood', 'frozen pizza', \n",
    "    'frozen produce', 'frozen vegan vegetarian', \n",
    "    'fruit vegetable snacks', 'grains rice dried goods', \n",
    "    'granola', 'hair care', 'honeys syrups nectars', \n",
    "    'hot cereal pancake mixes', 'hot dogs bacon sausage', \n",
    "    'ice cream ice', 'ice cream toppings', 'indian foods', \n",
    "    'instant foods', 'juice nectars', 'kitchen supplies', \n",
    "    'kosher foods', 'latino foods', 'laundry', \n",
    "    'lunch meat', 'marinades meat preparation', \n",
    "    'meat counter', 'milk', 'mint gum', 'missing_y', \n",
    "    'more household', 'muscles joints pain relief', \n",
    "    'nuts seeds dried fruit', 'oils vinegars', \n",
    "    'oral hygiene', 'other_y', 'other creams cheeses', \n",
    "    'packaged cheese', 'packaged meat', 'packaged poultry', \n",
    "    'packaged produce', 'packaged seafood', \n",
    "    'packaged vegetables fruits', 'paper goods', \n",
    "    'pasta sauce', 'pickled goods olives', \n",
    "    'plates bowls cups flatware', 'popcorn jerky', \n",
    "    'poultry counter', 'prepared meals', 'prepared soups salads', \n",
    "    'preserved dips spreads', 'protein meal replacements', \n",
    "    'red wines', 'refrigerated', 'refrigerated pudding desserts', \n",
    "    'salad dressing toppings', 'seafood counter', \n",
    "    'shave needs', 'skin care', 'soap', 'soft drinks', \n",
    "    'soup broth bouillon', 'soy lactosefree', \n",
    "    'specialty cheeses', 'specialty wines champagnes', \n",
    "    'spices seasonings', 'spirits', 'spreads', 'tea', \n",
    "    'tofu meat alternatives', 'tortillas flat bread', \n",
    "    'trail mix snack mix', 'trash bags liners', \n",
    "    'vitamins supplements', 'water seltzer sparkling water', \n",
    "    'white wines', 'yogurt']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = []\n",
    "for i in range(len(all_features)):\n",
    "    if isinstance(all_features[i], str):\n",
    "        feature_columns = [all_features[i]]\n",
    "    elif isinstance(all_features[i], list):\n",
    "        feature_columns = all_features[i]\n",
    "    y_tr, y_te = df_X_tr['in_cart'], df_X_te['in_cart']\n",
    "    X_tr, X_te = df_X_tr[feature_columns], \\\n",
    "                 df_X_te[feature_columns]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_tr = scaler.fit_transform(X_tr)\n",
    "    X_te = scaler.transform(X_te)\n",
    "\n",
    "    # oversample positive samples to be 40% of targets \n",
    "    ROS = imblearn.over_sampling.RandomOverSampler(random_state=159)\n",
    "    X_tr_rs, y_tr_rs = ROS.fit_sample(X_tr, y_tr)\n",
    "\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_tr_rs, y_tr_rs)\n",
    "    f1_scr = f1_score(lr.predict(X_te), y_te)\n",
    "#     print('Features used: {}'.format(feature_columns))\n",
    "#     print('F1 Score: {}'.format(f1_scr))\n",
    "    f1_scores.append(f1_scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = [\n",
    "    'P Order Frequency',\n",
    "    'UP Add to cart order',\n",
    "    'UP Mean Hour Of Day',\n",
    "    'U Total Orders',\n",
    "    'U Avg Cartsize',\n",
    "    'U Total Products',\n",
    "    'U Prior Orders Days', \n",
    "    'UP Prior Orders Days',\n",
    "    'Last Reorder',\n",
    "    'Max Consec Reorders',\n",
    "    'Departments',\n",
    "    'Aisles'\n",
    "]\n",
    "\n",
    "y_pos = np.arange(len(x_labels))\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.bar(y_pos, f1_scores, align='center', alpha=0.5)\n",
    "\n",
    "plt.xticks(y_pos, x_labels)\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score For Varying Features')\n",
    "\n",
    "# plt.bar(x_labels, f1_scores)\n",
    "# plt.xticks(x_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(x_labels, f1_scores)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_log_features = [\n",
    "    'user_product_times_ordered',\n",
    "    'user_product_add_to_cart_order_median',\n",
    "    'user_product_hour_of_day_mean',\n",
    "    'user_total_orders',\n",
    "    'user_avg_cartsize',\n",
    "    'user_total_products',\n",
    "#     'user_avg_days_since_prior_order', \n",
    "    'usadspo_0-5', 'usadspo_5-10', 'usadspo_10-15', \n",
    "         'usadspo_15-20', 'usadspo_20-25', 'usadspo_25-30', \n",
    "         'usadspo_firstTime',\n",
    "    'last_reorder',\n",
    "    'max_consec_reorders',\n",
    "    'alcohol', 'babies', 'bakery', 'beverages',\n",
    "        'breakfast', 'bulk', 'canned goods', 'dairy eggs', 'deli',\n",
    "        'dry goods pasta', 'frozen', 'household', 'international',\n",
    "        'meat seafood', 'pantry', 'personal care', 'pets',\n",
    "        'produce', 'snacks',\n",
    "    'air fresheners candles', 'asian foods', \n",
    "        'baby accessories', 'baby bath body care', \n",
    "        'baby food formula', 'bakery desserts', \n",
    "        'baking ingredients', 'baking supplies decor', \n",
    "        'beauty', 'beers coolers', 'body lotions soap', \n",
    "        'bread', 'breakfast bakery', 'breakfast bars pastries', \n",
    "        'bulk dried fruits vegetables', 'bulk grains rice dried goods', \n",
    "        'buns rolls', 'butter', 'candy chocolate', \n",
    "        'canned fruit applesauce', 'canned jarred vegetables', \n",
    "        'canned meals beans', 'canned meat seafood', \n",
    "        'cat food care', 'cereal', 'chips pretzels', \n",
    "        'cleaning products', 'cocoa drink mixes', \n",
    "        'coffee', 'cold flu allergy', 'condiments', \n",
    "        'cookies cakes', 'crackers', 'cream', 'deodorants', \n",
    "        'diapers wipes', 'digestion', 'dish detergents', \n",
    "        'dog food care', 'doughs gelatins bake mixes', \n",
    "        'dry pasta', 'eggs', 'energy granola bars', \n",
    "        'energy sports drinks', 'eye ear care', \n",
    "        'facial care', 'feminine care', 'first aid', \n",
    "        'food storage', 'fresh dips tapenades', \n",
    "        'fresh fruits', 'fresh herbs', 'fresh pasta', \n",
    "        'fresh vegetables', 'frozen appetizers sides', \n",
    "        'frozen breads doughs', 'frozen breakfast', \n",
    "        'frozen dessert', 'frozen juice', 'frozen meals', \n",
    "        'frozen meat seafood', 'frozen pizza', \n",
    "        'frozen produce', 'frozen vegan vegetarian', \n",
    "        'fruit vegetable snacks', 'grains rice dried goods', \n",
    "        'granola', 'hair care', 'honeys syrups nectars', \n",
    "        'hot cereal pancake mixes', 'hot dogs bacon sausage', \n",
    "        'ice cream ice', 'ice cream toppings', 'indian foods', \n",
    "        'instant foods', 'juice nectars', 'kitchen supplies', \n",
    "        'kosher foods', 'latino foods', 'laundry', \n",
    "        'lunch meat', 'marinades meat preparation', \n",
    "        'meat counter', 'milk', 'mint gum', 'missing_y', \n",
    "        'more household', 'muscles joints pain relief', \n",
    "        'nuts seeds dried fruit', 'oils vinegars', \n",
    "        'oral hygiene', 'other_y', 'other creams cheeses', \n",
    "        'packaged cheese', 'packaged meat', 'packaged poultry', \n",
    "        'packaged produce', 'packaged seafood', \n",
    "        'packaged vegetables fruits', 'paper goods', \n",
    "        'pasta sauce', 'pickled goods olives', \n",
    "        'plates bowls cups flatware', 'popcorn jerky', \n",
    "        'poultry counter', 'prepared meals', 'prepared soups salads', \n",
    "        'preserved dips spreads', 'protein meal replacements', \n",
    "        'red wines', 'refrigerated', 'refrigerated pudding desserts', \n",
    "        'salad dressing toppings', 'seafood counter', \n",
    "        'shave needs', 'skin care', 'soap', 'soft drinks', \n",
    "        'soup broth bouillon', 'soy lactosefree', \n",
    "        'specialty cheeses', 'specialty wines champagnes', \n",
    "        'spices seasonings', 'spirits', 'spreads', 'tea', \n",
    "        'tofu meat alternatives', 'tortillas flat bread', \n",
    "        'trail mix snack mix', 'trash bags liners', \n",
    "        'vitamins supplements', 'water seltzer sparkling water', \n",
    "        'white wines', 'yogurt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr, y_te = df_X_tr['in_cart'], df_X_te['in_cart']\n",
    "X_tr, X_te = df_X_tr[all_log_features], \\\n",
    "             df_X_te[all_log_features]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_tr = scaler.fit_transform(X_tr)\n",
    "X_te = scaler.transform(X_te)\n",
    "\n",
    "# oversample positive samples to be 40% of targets \n",
    "ROS = imblearn.over_sampling.RandomOverSampler(random_state=159)\n",
    "X_tr_rs, y_tr_rs = ROS.fit_sample(X_tr, y_tr)\n",
    "\n",
    "lr_af = LogisticRegression(n_jobs=-1)\n",
    "lr_af.fit(X_tr_rs, y_tr_rs)\n",
    "f1_scr = f1_score(lr_af.predict(X_te), y_te)\n",
    "#     print('Features used: {}'.format(feature_columns))\n",
    "print('F1 Score for All Features: {}'.format(f1_scr))\n",
    "print('Recall Score for All Features: {}'.format(recall_score(lr_af.predict(X_te), y_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sorted(list(zip(lr.coef_[0], all_log_features)), key=lambda x:x[0], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_features = ['user_product_times_ordered',\n",
    "        'user_product_add_to_cart_order_median',\n",
    "        'user_product_hour_of_day_mean',\n",
    "        'user_total_orders', 'user_avg_cartsize', 'user_total_products',\n",
    "        'user_avg_days_since_prior_order', 'user_product_average_days_since_prior_order','last_reorder', 'max_consec_reorders',\n",
    "        'alcohol', 'babies', 'bakery', 'beverages',\n",
    "            'breakfast', 'bulk', 'canned goods', 'dairy eggs', 'deli',\n",
    "            'dry goods pasta', 'frozen', 'household', 'international',\n",
    "            'meat seafood', 'pantry', 'personal care', 'pets',\n",
    "            'produce', 'snacks',\n",
    "        'air fresheners candles', 'asian foods', \n",
    "            'baby accessories', 'baby bath body care', \n",
    "            'baby food formula', 'bakery desserts', \n",
    "            'baking ingredients', 'baking supplies decor', \n",
    "            'beauty', 'beers coolers', 'body lotions soap', \n",
    "            'bread', 'breakfast bakery', 'breakfast bars pastries', \n",
    "            'bulk dried fruits vegetables', 'bulk grains rice dried goods', \n",
    "            'buns rolls', 'butter', 'candy chocolate', \n",
    "            'canned fruit applesauce', 'canned jarred vegetables', \n",
    "            'canned meals beans', 'canned meat seafood', \n",
    "            'cat food care', 'cereal', 'chips pretzels', \n",
    "            'cleaning products', 'cocoa drink mixes', \n",
    "            'coffee', 'cold flu allergy', 'condiments', \n",
    "            'cookies cakes', 'crackers', 'cream', 'deodorants', \n",
    "            'diapers wipes', 'digestion', 'dish detergents', \n",
    "            'dog food care', 'doughs gelatins bake mixes', \n",
    "            'dry pasta', 'eggs', 'energy granola bars', \n",
    "            'energy sports drinks', 'eye ear care', \n",
    "            'facial care', 'feminine care', 'first aid', \n",
    "            'food storage', 'fresh dips tapenades', \n",
    "            'fresh fruits', 'fresh herbs', 'fresh pasta', \n",
    "            'fresh vegetables', 'frozen appetizers sides', \n",
    "            'frozen breads doughs', 'frozen breakfast', \n",
    "            'frozen dessert', 'frozen juice', 'frozen meals', \n",
    "            'frozen meat seafood', 'frozen pizza', \n",
    "            'frozen produce', 'frozen vegan vegetarian', \n",
    "            'fruit vegetable snacks', 'grains rice dried goods', \n",
    "            'granola', 'hair care', 'honeys syrups nectars', \n",
    "            'hot cereal pancake mixes', 'hot dogs bacon sausage', \n",
    "            'ice cream ice', 'ice cream toppings', 'indian foods', \n",
    "            'instant foods', 'juice nectars', 'kitchen supplies', \n",
    "            'kosher foods', 'latino foods', 'laundry', \n",
    "            'lunch meat', 'marinades meat preparation', \n",
    "            'meat counter', 'milk', 'mint gum', 'missing_y', \n",
    "            'more household', 'muscles joints pain relief', \n",
    "            'nuts seeds dried fruit', 'oils vinegars', \n",
    "            'oral hygiene', 'other_y', 'other creams cheeses', \n",
    "            'packaged cheese', 'packaged meat', 'packaged poultry', \n",
    "            'packaged produce', 'packaged seafood', \n",
    "            'packaged vegetables fruits', 'paper goods', \n",
    "            'pasta sauce', 'pickled goods olives', \n",
    "            'plates bowls cups flatware', 'popcorn jerky', \n",
    "            'poultry counter', 'prepared meals', 'prepared soups salads', \n",
    "            'preserved dips spreads', 'protein meal replacements', \n",
    "            'red wines', 'refrigerated', 'refrigerated pudding desserts', \n",
    "            'salad dressing toppings', 'seafood counter', \n",
    "            'shave needs', 'skin care', 'soap', 'soft drinks', \n",
    "            'soup broth bouillon', 'soy lactosefree', \n",
    "            'specialty cheeses', 'specialty wines champagnes', \n",
    "            'spices seasonings', 'spirits', 'spreads', 'tea', \n",
    "            'tofu meat alternatives', 'tortillas flat bread', \n",
    "            'trail mix snack mix', 'trash bags liners', \n",
    "            'vitamins supplements', 'water seltzer sparkling water', \n",
    "            'white wines', 'yogurt']\n",
    "\n",
    "y_tr, y_te = df_X_tr['in_cart'], df_X_te['in_cart']\n",
    "X_tr, X_te = df_X_tr[rf_features].copy(), \\\n",
    "             df_X_te[rf_features].copy()\n",
    "X_tr[['user_product_average_days_since_prior_order']]=X_tr[['user_product_average_days_since_prior_order']].fillna(-1)\n",
    "X_te[['user_product_average_days_since_prior_order']]=X_te[['user_product_average_days_since_prior_order']].fillna(-1)\n",
    "\n",
    "# oversample positive samples\n",
    "ROS = imblearn.over_sampling.RandomOverSampler(random_state=159)\n",
    "X_tr_rs, y_tr_rs = ROS.fit_sample(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to dataframe\n",
    "X_tr_rs = pd.DataFrame(X_tr_rs)\n",
    "X_tr_rs.columns=rf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset dtypes\n",
    "temp_dtypes = {\n",
    "    'user_product_times_ordered': np.int32,\n",
    "    'user_product_add_to_cart_order_median': np.float32,\n",
    "    'user_product_hour_of_day_mean': np.float32,\n",
    "    'user_total_orders': np.int32,\n",
    "    'user_avg_cartsize': np.float32,\n",
    "    'user_total_products': np.int32,\n",
    "    'user_avg_days_since_prior_order': np.float16,\n",
    "    'user_product_average_days_since_prior_order': np.float16,\n",
    "    'last_reorder': np.int64,\n",
    "    'max_consec_reorders': np.int64,\n",
    "    'alcohol': np.uint8,\n",
    "    'babies': np.uint8,\n",
    "    'bakery': np.uint8,\n",
    "    'beverages': np.uint8,\n",
    "    'breakfast': np.uint8,\n",
    "    'bulk': np.uint8,\n",
    "    'canned goods': np.uint8,\n",
    "    'dairy eggs': np.uint8,\n",
    "    'deli': np.uint8,\n",
    "    'dry goods pasta': np.uint8,\n",
    "    'frozen': np.uint8,\n",
    "    'household': np.uint8,\n",
    "    'international': np.uint8,\n",
    "    'meat seafood': np.uint8,\n",
    "#     'missing': np.uint8,\n",
    "#     'other': np.uint8,\n",
    "    'pantry': np.uint8,\n",
    "    'personal care': np.uint8,\n",
    "    'pets': np.uint8,\n",
    "    'produce': np.uint8,\n",
    "    'snacks': np.uint8,\n",
    "    'air fresheners candles': np.uint8, 'asian foods': np.uint8, 'baby accessories': np.uint8, 'baby bath body care': np.uint8, 'baby food formula': np.uint8, 'bakery desserts': np.uint8, 'baking ingredients': np.uint8, 'baking supplies decor': np.uint8, 'beauty': np.uint8, 'beers coolers': np.uint8, 'body lotions soap': np.uint8, 'bread': np.uint8, 'breakfast bakery': np.uint8, 'breakfast bars pastries': np.uint8, 'bulk dried fruits vegetables': np.uint8, 'bulk grains rice dried goods': np.uint8, 'buns rolls': np.uint8, 'butter': np.uint8, 'candy chocolate': np.uint8, 'canned fruit applesauce': np.uint8, 'canned jarred vegetables': np.uint8, 'canned meals beans': np.uint8, 'canned meat seafood': np.uint8, 'cat food care': np.uint8, 'cereal': np.uint8, 'chips pretzels': np.uint8, 'cleaning products': np.uint8, 'cocoa drink mixes': np.uint8, 'coffee': np.uint8, 'cold flu allergy': np.uint8, 'condiments': np.uint8, 'cookies cakes': np.uint8, 'crackers': np.uint8, 'cream': np.uint8, 'deodorants': np.uint8, 'diapers wipes': np.uint8, 'digestion': np.uint8, 'dish detergents': np.uint8, 'dog food care': np.uint8, 'doughs gelatins bake mixes': np.uint8, 'dry pasta': np.uint8, 'eggs': np.uint8, 'energy granola bars': np.uint8, 'energy sports drinks': np.uint8, 'eye ear care': np.uint8, 'facial care': np.uint8, 'feminine care': np.uint8, 'first aid': np.uint8, 'food storage': np.uint8, 'fresh dips tapenades': np.uint8, 'fresh fruits': np.uint8, 'fresh herbs': np.uint8, 'fresh pasta': np.uint8, 'fresh vegetables': np.uint8, 'frozen appetizers sides': np.uint8, 'frozen breads doughs': np.uint8, 'frozen breakfast': np.uint8, 'frozen dessert': np.uint8, 'frozen juice': np.uint8, 'frozen meals': np.uint8, 'frozen meat seafood': np.uint8, 'frozen pizza': np.uint8, 'frozen produce': np.uint8, 'frozen vegan vegetarian': np.uint8, 'fruit vegetable snacks': np.uint8, 'grains rice dried goods': np.uint8, 'granola': np.uint8, 'hair care': np.uint8, 'honeys syrups nectars': np.uint8, 'hot cereal pancake mixes': np.uint8, 'hot dogs bacon sausage': np.uint8, 'ice cream ice': np.uint8, 'ice cream toppings': np.uint8, 'indian foods': np.uint8, 'instant foods': np.uint8, 'juice nectars': np.uint8, 'kitchen supplies': np.uint8, 'kosher foods': np.uint8, 'latino foods': np.uint8, 'laundry': np.uint8, 'lunch meat': np.uint8, 'marinades meat preparation': np.uint8, 'meat counter': np.uint8, 'milk': np.uint8, 'mint gum': np.uint8, 'missing_y': np.uint8, 'more household': np.uint8, 'muscles joints pain relief': np.uint8, 'nuts seeds dried fruit': np.uint8, 'oils vinegars': np.uint8, 'oral hygiene': np.uint8, 'other_y': np.uint8, 'other creams cheeses': np.uint8, 'packaged cheese': np.uint8, 'packaged meat': np.uint8, 'packaged poultry': np.uint8, 'packaged produce': np.uint8, 'packaged seafood': np.uint8, 'packaged vegetables fruits': np.uint8, 'paper goods': np.uint8, 'pasta sauce': np.uint8, 'pickled goods olives': np.uint8, 'plates bowls cups flatware': np.uint8, 'popcorn jerky': np.uint8, 'poultry counter': np.uint8, 'prepared meals': np.uint8, 'prepared soups salads': np.uint8, 'preserved dips spreads': np.uint8, 'protein meal replacements': np.uint8, 'red wines': np.uint8, 'refrigerated': np.uint8, 'refrigerated pudding desserts': np.uint8, 'salad dressing toppings': np.uint8, 'seafood counter': np.uint8, 'shave needs': np.uint8, 'skin care': np.uint8, 'soap': np.uint8, 'soft drinks': np.uint8, 'soup broth bouillon': np.uint8, 'soy lactosefree': np.uint8, 'specialty cheeses': np.uint8, 'specialty wines champagnes': np.uint8, 'spices seasonings': np.uint8, 'spirits': np.uint8, 'spreads': np.uint8, 'tea': np.uint8, 'tofu meat alternatives': np.uint8, 'tortillas flat bread': np.uint8, 'trail mix snack mix': np.uint8, 'trash bags liners': np.uint8, 'vitamins supplements': np.uint8, 'water seltzer sparkling water': np.uint8, 'white wines': np.uint8, 'yogurt': np.uint8    \n",
    "}\n",
    "\n",
    "for col, col_type in temp_dtypes.items():\n",
    "    X_tr_rs[col] = X_tr_rs[col].astype(col_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmodel = RandomForestClassifier(n_estimators = 750,\n",
    "                                min_samples_leaf = 20, n_jobs=-1, max_features='sqrt')\n",
    "rfmodel.fit(X_tr_rs, y_tr_rs)\n",
    "y_pred = rfmodel.predict(X_te)\n",
    "print('Test F1 Score: {}'.format(f1_score(y_pred, y_te)))\n",
    "y_tr_pred = rfmodel.predict(X_tr)\n",
    "print('Training F1 Score: {}'.format(f1_score(y_tr_pred, y_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmodel = RandomForestClassifier(n_estimators = 500,\n",
    "                                min_samples_leaf = 20, n_jobs=-1, max_features='sqrt')\n",
    "rfmodel.fit(X_tr_rs, y_tr_rs)\n",
    "y_pred = rfmodel.predict(X_te)\n",
    "print('Test F1 Score: {}'.format(f1_score(y_pred, y_te)))\n",
    "y_tr_pred = rfmodel.predict(X_tr)\n",
    "print('Training F1 Score: {}'.format(f1_score(y_tr_pred, y_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmodel = RandomForestClassifier(n_estimators = 1000,\n",
    "                                min_samples_leaf = 20, n_jobs=-1, max_features='sqrt')\n",
    "rfmodel.fit(X_tr_rs, y_tr_rs)\n",
    "y_pred = rfmodel.predict(X_te)\n",
    "print('Test F1 Score: {}'.format(f1_score(y_pred, y_te)))\n",
    "y_tr_pred = rfmodel.predict(X_tr)\n",
    "print('Training F1 Score: {}'.format(f1_score(y_tr_pred, y_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmodel = RandomForestClassifier(n_estimators = 500,\n",
    "                                min_samples_leaf = 15, n_jobs=-1, max_features='sqrt')\n",
    "rfmodel.fit(X_tr_rs, y_tr_rs)\n",
    "y_pred = rfmodel.predict(X_te)\n",
    "print('Test F1 Score: {}'.format(f1_score(y_pred, y_te)))\n",
    "y_tr_pred = rfmodel.predict(X_tr)\n",
    "print('Training F1 Score: {}'.format(f1_score(y_tr_pred, y_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmodel = RandomForestClassifier(n_estimators = 500,\n",
    "                                min_samples_leaf = 10, n_jobs=-1, max_features='sqrt')\n",
    "rfmodel.fit(X_tr_rs, y_tr_rs)\n",
    "y_pred = rfmodel.predict(X_te)\n",
    "print('Test F1 Score: {}'.format(f1_score(y_pred, y_te)))\n",
    "y_tr_pred = rfmodel.predict(X_tr)\n",
    "print('Training F1 Score: {}'.format(f1_score(y_tr_pred, y_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfmodel = RandomForestClassifier(n_estimators = 500,\n",
    "                                min_samples_leaf = 5, n_jobs=-1, max_features='sqrt')\n",
    "rfmodel.fit(X_tr_rs, y_tr_rs)\n",
    "y_pred = rfmodel.predict(X_te)\n",
    "print('Test F1 Score: {}'.format(f1_score(y_pred, y_te)))\n",
    "print('Test Recall Score: {}'.format(recall_score(y_pred, y_te)))\n",
    "\n",
    "y_tr_pred = rfmodel.predict(X_tr)\n",
    "print('Training F1 Score: {}'.format(f1_score(y_tr_pred, y_tr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = XGBClassifier( \n",
    "                       n_estimators=40000, #arbitrary large number\n",
    "                       max_depth=7,\n",
    "                       objective='binary:logistic', #new objective\n",
    "                       learning_rate=.05, \n",
    "                       subsample=.8,\n",
    "                       min_child_weight=12,\n",
    "                       colsample_bytree=.8,\n",
    "                       n_jobs=-1\n",
    "                      )\n",
    "eval_set=[(X_tr_rs, y_tr_rs),(X_te,y_te)]\n",
    "\n",
    "fit_model = gbm.fit( \n",
    "                    X_tr_rs, y_tr_rs, \n",
    "                    eval_set=eval_set,\n",
    "                    eval_metric='error', #new evaluation metric: classification error (could also use AUC, e.g.)\n",
    "                    early_stopping_rounds=50,\n",
    "                    verbose=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_te, ntree_limit=gbm.best_ntree_limit)\n",
    "print('Test F1 Score: {}'.format(f1_score(y_pred, y_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = XGBClassifier( \n",
    "                       n_estimators=40000, #arbitrary large number\n",
    "                       max_depth=6,\n",
    "                       objective='binary:logistic', #new objective\n",
    "                       learning_rate=.05, \n",
    "                       subsample=.8,\n",
    "                       min_child_weight=10,\n",
    "                       colsample_bytree=.8,\n",
    "                       n_jobs=-1\n",
    "                      )\n",
    "eval_set=[(X_tr_rs, y_tr_rs),(X_te,y_te)]\n",
    "\n",
    "fit_model = gbm.fit( \n",
    "                    X_tr_rs, y_tr_rs, \n",
    "                    eval_set=eval_set,\n",
    "                    eval_metric='error', #new evaluation metric: classification error (could also use AUC, e.g.)\n",
    "                    early_stopping_rounds=50,\n",
    "                    verbose=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_te, ntree_limit=gbm.best_ntree_limit)\n",
    "print('Test F1 Score: {}'.format(f1_score(y_pred, y_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = XGBClassifier( \n",
    "                       n_estimators=40000, #arbitrary large number\n",
    "                       max_depth=8,\n",
    "                       objective='binary:logistic', #new objective\n",
    "                       learning_rate=.05, \n",
    "                       subsample=.8,\n",
    "                       min_child_weight=20,\n",
    "                       colsample_bytree=.8,\n",
    "                       n_jobs=-1\n",
    "                      )\n",
    "eval_set=[(X_tr_rs, y_tr_rs),(X_te,y_te)]\n",
    "\n",
    "fit_model = gbm.fit( \n",
    "                    X_tr_rs, y_tr_rs, \n",
    "                    eval_set=eval_set,\n",
    "                    eval_metric='error', #new evaluation metric: classification error (could also use AUC, e.g.)\n",
    "                    early_stopping_rounds=50,\n",
    "                    verbose=True\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_te, ntree_limit=gbm.best_ntree_limit)\n",
    "print('Test F1 Score: {}'.format(f1_score(y_pred, y_te)))\n",
    "print('Test Recall Score: {}'.format(recall_score(y_pred, y_te)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_scores = gbm.get_booster().get_score(importance_type='gain') #extract raw gain scores\n",
    "sorted(gbm_scores.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(gbm, importance_type='gain', max_num_features=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X.in_cart.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
